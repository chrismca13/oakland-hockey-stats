{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade s3fs fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import fsspec\n",
    "\n",
    "# df = pd.read_csv('s3://gang-green-hockey/OaklandHockeyData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Oakland Gang Green Hockey All Time Stats\n",
    "# Chris McAllister\n",
    " \n",
    "# This script gathers all the Oakland Hockey Stats for all 4 GG teams, for every season that which the website has data.\n",
    " \n",
    "# Oultine:\n",
    "# 1) Import libraries\n",
    "# 2) Establish mapping of GG Team ID's in URL to Team Names (Gang Green 1, 2, etc.)\n",
    "# 3/4) Get a base dataset of all the players who played for Gang Green in our season dim range\n",
    "# 3/4) Read in a CSV that converts SeasonIDs to the Season Name\n",
    "# 5) Light data manipulation. Removing columns, create Points per Game metric, etc.\n",
    "\n",
    "# 1) Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Ignore any warning messages\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 3/4) Get a base dataset of all the players who played for Gang Green in our season dim range\n",
    "# This needs to be run occasionally, when a new season starts. Upload it to S3 when done.\n",
    "def initial_web_data(season_dim_csv):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes in one arguments:\n",
    "\n",
    "    season_dim_csv (csv): A csv that acts as a dimensional table for all the seasons we want to pull in.\n",
    "                          One row is one season. Key is the ID of that season according to the website\n",
    "                          Other attributes includes the year, season name (Fall 2021, eg.), etc.\n",
    "\n",
    "    returns a dataframe that is at the player-season grain of all GG players that played in a season in our season_dim_csv file. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print('Running For every season and division')\n",
    "    \n",
    "    # Establish empty df  of our columns\n",
    "    df_main = pd.DataFrame(columns = ['Name', '#', 'Team', 'GP', 'Goals', 'Ass.', 'Hat', 'Min', 'Pts/Game', 'Pts'])\n",
    "\n",
    "    # May need to change this if the league adds a new division\n",
    "    division_dict = {'99': 'D1',\n",
    "                     '210': 'D3',\n",
    "                     '104': 'D5', \n",
    "                     '98' : 'D6',\n",
    "                     '138': 'D7',\n",
    "                     '198': 'D8',\n",
    "                     '211': 'D9'}\n",
    "\n",
    "    for index, season_id in enumerate(season_dim_csv['SeasonID']):\n",
    "        for league_id in list(division_dict.keys()):\n",
    "\n",
    "            url = 'https://stats.sharksice.timetoscore.com/display-league-stats?stat_class=1&league=27&season=' + str(season_id) + '&level=' + str(league_id) + '&conf=0'\n",
    "\n",
    "            # There are gaps in season IDs (for example there's no season #34). \n",
    "            # This would cause an error when reading the URL so we need to handle that with the try / except code block below. \n",
    "            try:\n",
    "                df = pd.read_html(url)\n",
    "                df[0].columns = df[0].columns.droplevel()\n",
    "                df[0]['SeasonID'] = int(season_id)\n",
    "                df[0]['division'] = str(division_dict[league_id])\n",
    "\n",
    "                df_main = pd.concat([df_main, df[0]])\n",
    "\n",
    "            except:\n",
    "                print('Season ID: ' + str(season_id) + ' Division ID: ' + str(league_id) + ' does not exist. Skipping...')\n",
    "                print(url)\n",
    "\n",
    "        if index % 3 == 0:\n",
    "            print(f'Processed {index} seasons so far')\n",
    "\n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Read in a CSV that converts SeasonIDs to the Season Name\n",
    "season_dim = pd.read_csv('Input_data/OaklandHockeySeasonDim.csv')\n",
    "# all_players = initial_web_data(season_dim)\n",
    "# all_players.to_csv('Output_data/ALL_OaklandHockeyData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_season(s3_path = 's3://gang-green-hockey/ALL_OaklandHockeyData.csv'):\n",
    "    \"\"\"\n",
    "    This function updates the dataset in S3 with the latest data every day.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(s3_path)\n",
    "\n",
    "    max_season = df['SeasonID'].max()\n",
    "\n",
    "    df_drop_curr_season = df[df['SeasonID'] != max_season]\n",
    "\n",
    "    # May need to change this if the league adds a new division\n",
    "    division_dict = {'99': 'D1',\n",
    "                     '210': 'D3',\n",
    "                     '104': 'D5', \n",
    "                     '98' : 'D6',\n",
    "                     '138': 'D7',\n",
    "                     '198': 'D8',\n",
    "                     '211': 'D9'}\n",
    "\n",
    "    for league_id in list(division_dict.keys()):\n",
    "\n",
    "        url = 'https://stats.sharksice.timetoscore.com/display-league-stats?stat_class=1&league=27&season=' + str(int(max_season)) + '&level=' + str(league_id) + '&conf=0'\n",
    "\n",
    "        # There are gaps in season IDs (for example there's no season #34). \n",
    "        # This would cause an error when reading the URL so we need to handle that with the try / except code block below. \n",
    "        try:\n",
    "            df_curr = pd.read_html(url)\n",
    "            df_curr[0].columns = df_curr[0].columns.droplevel()\n",
    "            df_curr[0]['SeasonID'] = int(max_season)\n",
    "            df_curr[0]['division'] = str(division_dict[league_id])\n",
    "\n",
    "            df_drop_curr_season = pd.concat([df_drop_curr_season, df_curr[0]])\n",
    "\n",
    "        except:\n",
    "            print('Division ID: ' + str(league_id) + ' does not exist. Skipping...')\n",
    "            print(url)\n",
    "    \n",
    "    return df_drop_curr_season\n",
    "\n",
    "data = update_current_season()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>#</th>\n",
       "      <th>Team</th>\n",
       "      <th>GP</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Ass.</th>\n",
       "      <th>Hat</th>\n",
       "      <th>Min</th>\n",
       "      <th>Pts/Game</th>\n",
       "      <th>Pts</th>\n",
       "      <th>SeasonID</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Kelly</td>\n",
       "      <td>16</td>\n",
       "      <td>Skateful Dead</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryan mountford</td>\n",
       "      <td>13</td>\n",
       "      <td>Chicos</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alex Bernstein</td>\n",
       "      <td>66</td>\n",
       "      <td>Bay Area Battalion</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erik Davidson</td>\n",
       "      <td>9</td>\n",
       "      <td>Bonefish</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1.83</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>john arceo</td>\n",
       "      <td>5</td>\n",
       "      <td>SD 2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.08</td>\n",
       "      <td>27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name   #                Team  GP  Goals  Ass.  Hat  Min  \\\n",
       "0       Tim Kelly  16       Skateful Dead  14     15    20    1    2   \n",
       "1  ryan mountford  13              Chicos  15     22    11    3   20   \n",
       "2  Alex Bernstein  66  Bay Area Battalion  16     16    17    1    8   \n",
       "3   Erik Davidson   9            Bonefish  18     15    18    1   16   \n",
       "4      john arceo   5              SD 2.0  13     15    12    2    6   \n",
       "\n",
       "   Pts/Game  Pts  SeasonID division  \n",
       "0      2.50   35      11.0       D1  \n",
       "1      2.20   33      11.0       D1  \n",
       "2      2.06   33      11.0       D1  \n",
       "3      1.83   33      11.0       D1  \n",
       "4      2.08   27      11.0       D1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Light data manipulation. Removing columns, create Points per Game metric, etc.\n",
    "def data_manip(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Argument(s):\n",
    "    A df at the grain of player-season.\n",
    "    It it the outuput of the previous function call base_web_data()\n",
    "\n",
    "    returns a manipulated df where a player's stats are aggregated to the player grain. \n",
    "    \"\"\"\n",
    "    # Cast as integers so the join below works (otherwise it won't recognize 5.0 as 5, etc.)\n",
    "    # df['SeasonID'] = df['SeasonID'].astype(int) \n",
    "    # df['TeamID'] = df['TeamID'].astype(int)\n",
    "    # Convert season IDs (#40) to Season Name (Fall 2017)\n",
    "    df_final = pd.merge(left = df, right = season_dim, how = 'left', left_on = 'SeasonID', right_on = 'SeasonID')\n",
    "\n",
    "    # Only select necessarry columns\n",
    "    col = ['Name', '#', 'Team', 'GP', 'Goals', 'Ass.', 'Hat', 'Min', 'Pts/Game', 'Pts', 'SeasonID']\n",
    "\n",
    "    df_final = df_final[col]\n",
    "    df_final.drop(columns = ['Pts/Game', '#'], inplace = True)\n",
    "\n",
    "    # Create a GPG and Pts per game metric. \n",
    "    df_final['GPG'] = df_final['Goals'] / df_final['GP']\n",
    "    df_final['Pts_PG'] = df_final['Pts'] / df_final['GP']\n",
    "\n",
    "    df_final['SeasonID'] = df_final['SeasonID'].astype(int) \n",
    "    # df_final['TeamID'] = df_final['TeamID'].astype(int)\n",
    "    \n",
    "    # Get team name from Team ID (GG 1, 3, etc.)\n",
    "    # manip_df = pd.merge(left = df_final, right = team_dim, how = 'left', left_on = 'TeamID', right_on = 'TeamID')\n",
    "    df_final['lastupdated'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    df_final = pd.merge(left = df_final, right = season_dim, how = 'left', left_on = 'SeasonID', right_on = 'SeasonID')\n",
    "\n",
    "    # Ouput results to CSV\n",
    "    df_final.to_csv('Output_data/OaklandHockeyData.csv', index = False)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "df = data_manip(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Name'] == 'CHRISTOPHER MCALLISTER']['Goals'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
